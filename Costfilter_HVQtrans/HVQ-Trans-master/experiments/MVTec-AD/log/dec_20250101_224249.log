[2025-01-01 22:42:49,545][   train_val.py][line:  88][    INFO] args: Namespace(config='./config_visa.yaml', evaluate=False, local_rank=None, train_only_four_decoder=False)
[2025-01-01 22:42:49,548][   train_val.py][line:  89][    INFO] config: {'criterion': [{'kwargs': {'weight': 1.0},
                'name': 'FeatureMSELoss',
                'type': 'FeatureMSELoss'}],
 'dataset': {'batch_size': 16,
             'image_reader': {'kwargs': {'color_mode': 'RGB',
                                         'image_dir': '/home/customer/Desktop/ZZ/anomaly/GLAD-main/hdd/Datasets/VisA_pytorch'},
                              'type': 'opencv'},
             'input_size': [224, 224],
             'pixel_mean': [0.485, 0.456, 0.406],
             'pixel_std': [0.229, 0.224, 0.225],
             'test': {'meta_file': '../../data/VISA/test.json'},
             'train': {'hflip': False,
                       'meta_file': '../../data/VISA/train.json',
                       'rebalance': False,
                       'rotate': False,
                       'vflip': False},
             'type': 'custom',
             'workers': 4},
 'evaluator': {'eval_dir': './result_eval_temp',
               'key_metric': 'mean_max_auc',
               'metrics': {'auc': [{'name': 'std'},
                                   {'kwargs': {'avgpool_size': [16, 16]},
                                    'name': 'max'},
                                   {'name': 'pixel'}]},
               'save_dir': 'result_eval_temp',
               'vis_compound': {'max_score': None,
                                'min_score': None,
                                'save_dir': 'checkpoints/HVQ_TR_switch_OT/vis_compound_HVQ_TR_switch_OT/visual_VisA'}},
 'exp_path': '.',
 'frozen_layers': ['backbone'],
 'log_path': './log/',
 'net': [{'frozen': True,
          'kwargs': {'outlayers': [1, 2, 3, 4], 'pretrained': True},
          'name': 'backbone',
          'type': 'models.backbones.efficientnet_b4'},
         {'kwargs': {'outstrides': [16]},
          'name': 'neck',
          'prev': 'backbone',
          'type': 'models.necks.MFCN'},
         {'kwargs': {'activation': 'relu',
                     'dim_feedforward': 1024,
                     'dropout': 0.1,
                     'feature_jitter': {'prob': 1.0, 'scale': 20.0},
                     'hidden_dim': 256,
                     'initializer': {'method': 'xavier_uniform'},
                     'neighbor_mask': {'mask': [True, True, True],
                                       'neighbor_size': [7, 7]},
                     'nhead': 8,
                     'normalize_before': False,
                     'num_decoder_layers': 4,
                     'num_encoder_layers': 4,
                     'pos_embed_type': 'learned',
                     'save_recon': {'save_dir': 'result_recon'}},
          'name': 'reconstruction',
          'prev': 'neck',
          'type': 'models.reconstructions.HVQ_TR_switch_OT'}],
 'port': 11111,
 'random_seed': 1234,
 'save_path': './checkpoints/HVQ_TR_switch_OT_VisA',
 'saver': {'always_save': False,
           'auto_resume': False,
           'load_path': 'checkpoints',
           'log_dir': 'log/',
           'resume_model': '/home/customer/Desktop/ZZ/anomaly/HVQ-Trans-master/experiments/MVTec-AD/checkpoints/HVQ_TR_switch_OT_VisA/ckpt_best.pth.tar',
           'save_dir': 'checkpoints/HVQ_TR_switch_OT_VisA'},
 'trainer': {'clip_max_norm': 0.1,
             'lr_scheduler': {'kwargs': {'gamma': 0.1, 'step_size': 800},
                              'type': 'StepLR'},
             'max_epoch': 1000,
             'optimizer': {'kwargs': {'betas': [0.9, 0.999],
                                      'lr': 0.0001,
                                      'weight_decay': 0.0001},
                           'type': 'AdamW'},
             'print_freq_step': 80,
             'tb_freq_step': 1,
             'val_freq_epoch': 10},
 'version': 'v1.0.0'}
[2025-01-01 22:43:03,958][       utils.py][line: 719][    INFO]  not exist, load from https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b4-6ed6700e.pth
[2025-01-01 22:43:05,207][       utils.py][line: 740][    INFO] Loaded ImageNet pretrained efficientnet-b4
[2025-01-01 22:43:14,900][   train_val.py][line: 119][    INFO] layers: ['backbone', 'neck', 'reconstruction']
[2025-01-01 22:43:14,901][   train_val.py][line: 120][    INFO] active layers: ['reconstruction', 'neck']
[2025-01-01 22:43:40,761][custom_dataset.py][line:  41][    INFO] building CustomDataset from: ../../data/VISA/train.json
[2025-01-01 22:43:40,896][custom_dataset.py][line:  41][    INFO] building CustomDataset from: ../../data/VISA/test.json
[2025-01-01 22:44:02,506][   train_val.py][line: 306][    INFO] Epoch: [600/1000]	Iter: [324721/542000]	Time 0.21 (0.34)	Data 0.00 (0.10)	Loss 10.46819 (10.03767)	LR 0.00010	
[2025-01-01 22:44:30,929][   train_val.py][line: 306][    INFO] Epoch: [600/1000]	Iter: [324801/542000]	Time 0.18 (0.36)	Data 0.00 (0.12)	Loss 10.02299 (10.07418)	LR 0.00010	
[2025-01-01 22:44:57,193][   train_val.py][line: 306][    INFO] Epoch: [600/1000]	Iter: [324881/542000]	Time 0.20 (0.33)	Data 0.00 (0.10)	Loss 9.13254 (9.97970)	LR 0.00010	
[2025-01-01 22:45:22,734][   train_val.py][line: 306][    INFO] Epoch: [600/1000]	Iter: [324961/542000]	Time 0.22 (0.32)	Data 0.00 (0.09)	Loss 9.73737 (9.89423)	LR 0.00010	
[2025-01-01 22:45:49,161][   train_val.py][line: 306][    INFO] Epoch: [600/1000]	Iter: [325041/542000]	Time 0.26 (0.33)	Data 0.00 (0.10)	Loss 10.53492 (10.03653)	LR 0.00010	
[2025-01-01 22:46:14,197][   train_val.py][line: 306][    INFO] Epoch: [600/1000]	Iter: [325121/542000]	Time 0.22 (0.31)	Data 0.00 (0.08)	Loss 10.23686 (9.91893)	LR 0.00010	
[2025-01-01 22:46:40,310][   train_val.py][line: 306][    INFO] Epoch: [601/1000]	Iter: [325201/542000]	Time 1.38 (1.38)	Data 1.07 (1.07)	Loss 8.98883 (8.98883)	LR 0.00010	
[2025-01-01 22:46:58,929][   train_val.py][line: 306][    INFO] Epoch: [601/1000]	Iter: [325281/542000]	Time 0.26 (0.23)	Data 0.00 (0.00)	Loss 8.87891 (9.93503)	LR 0.00010	
[2025-01-01 22:47:18,636][   train_val.py][line: 306][    INFO] Epoch: [601/1000]	Iter: [325361/542000]	Time 0.18 (0.25)	Data 0.00 (0.00)	Loss 9.44788 (9.95199)	LR 0.00010	
[2025-01-01 22:47:37,763][   train_val.py][line: 306][    INFO] Epoch: [601/1000]	Iter: [325441/542000]	Time 0.19 (0.24)	Data 0.00 (0.00)	Loss 9.46632 (9.83492)	LR 0.00010	
[2025-01-01 22:47:56,699][   train_val.py][line: 306][    INFO] Epoch: [601/1000]	Iter: [325521/542000]	Time 0.22 (0.24)	Data 0.00 (0.00)	Loss 10.46507 (10.18739)	LR 0.00010	
[2025-01-01 22:48:16,325][   train_val.py][line: 306][    INFO] Epoch: [601/1000]	Iter: [325601/542000]	Time 0.26 (0.25)	Data 0.00 (0.00)	Loss 10.60602 (10.01715)	LR 0.00010	
[2025-01-01 22:48:35,134][   train_val.py][line: 306][    INFO] Epoch: [601/1000]	Iter: [325681/542000]	Time 0.32 (0.23)	Data 0.00 (0.00)	Loss 10.91771 (10.06853)	LR 0.00010	
[2025-01-01 22:48:54,987][   train_val.py][line: 306][    INFO] Epoch: [602/1000]	Iter: [325761/542000]	Time 0.26 (0.28)	Data 0.00 (0.05)	Loss 10.72079 (10.17596)	LR 0.00010	
[2025-01-01 22:49:13,927][   train_val.py][line: 306][    INFO] Epoch: [602/1000]	Iter: [325841/542000]	Time 0.29 (0.24)	Data 0.00 (0.00)	Loss 9.58162 (9.94119)	LR 0.00010	
[2025-01-01 22:49:33,161][   train_val.py][line: 306][    INFO] Epoch: [602/1000]	Iter: [325921/542000]	Time 0.23 (0.24)	Data 0.01 (0.00)	Loss 9.91026 (9.97666)	LR 0.00010	
[2025-01-01 22:49:52,316][   train_val.py][line: 306][    INFO] Epoch: [602/1000]	Iter: [326001/542000]	Time 0.19 (0.24)	Data 0.00 (0.00)	Loss 9.91044 (10.00827)	LR 0.00010	
[2025-01-01 22:50:11,780][   train_val.py][line: 306][    INFO] Epoch: [602/1000]	Iter: [326081/542000]	Time 0.21 (0.24)	Data 0.00 (0.00)	Loss 12.13695 (10.05664)	LR 0.00010	
[2025-01-01 22:50:31,232][   train_val.py][line: 306][    INFO] Epoch: [602/1000]	Iter: [326161/542000]	Time 0.29 (0.24)	Data 0.00 (0.00)	Loss 9.57114 (10.04727)	LR 0.00010	
[2025-01-01 22:50:50,837][   train_val.py][line: 306][    INFO] Epoch: [602/1000]	Iter: [326241/542000]	Time 0.33 (0.24)	Data 0.00 (0.00)	Loss 10.50367 (9.89954)	LR 0.00010	
[2025-01-01 22:51:11,805][   train_val.py][line: 306][    INFO] Epoch: [603/1000]	Iter: [326321/542000]	Time 0.35 (0.27)	Data 0.00 (0.03)	Loss 9.35140 (9.90154)	LR 0.00010	
[2025-01-01 22:51:30,973][   train_val.py][line: 306][    INFO] Epoch: [603/1000]	Iter: [326401/542000]	Time 0.23 (0.24)	Data 0.00 (0.00)	Loss 9.08194 (9.99674)	LR 0.00010	
[2025-01-01 22:51:50,630][   train_val.py][line: 306][    INFO] Epoch: [603/1000]	Iter: [326481/542000]	Time 0.24 (0.25)	Data 0.00 (0.00)	Loss 9.80001 (9.99749)	LR 0.00010	
[2025-01-01 22:52:09,925][   train_val.py][line: 306][    INFO] Epoch: [603/1000]	Iter: [326561/542000]	Time 0.24 (0.24)	Data 0.00 (0.00)	Loss 10.41879 (9.89149)	LR 0.00010	
[2025-01-01 22:52:29,706][   train_val.py][line: 306][    INFO] Epoch: [603/1000]	Iter: [326641/542000]	Time 0.22 (0.25)	Data 0.00 (0.00)	Loss 10.40442 (10.03404)	LR 0.00010	
[2025-01-01 22:52:51,522][   train_val.py][line: 306][    INFO] Epoch: [603/1000]	Iter: [326721/542000]	Time 0.23 (0.27)	Data 0.00 (0.00)	Loss 11.60695 (9.97252)	LR 0.00010	
[2025-01-01 22:53:13,290][   train_val.py][line: 306][    INFO] Epoch: [603/1000]	Iter: [326801/542000]	Time 0.32 (0.27)	Data 0.00 (0.00)	Loss 8.92607 (9.99123)	LR 0.00010	
[2025-01-01 22:53:38,494][   train_val.py][line: 306][    INFO] Epoch: [604/1000]	Iter: [326881/542000]	Time 0.63 (0.33)	Data 0.04 (0.03)	Loss 10.02828 (9.93687)	LR 0.00010	
[2025-01-01 22:54:04,951][   train_val.py][line: 306][    INFO] Epoch: [604/1000]	Iter: [326961/542000]	Time 0.30 (0.33)	Data 0.00 (0.00)	Loss 10.08605 (9.72851)	LR 0.00010	
